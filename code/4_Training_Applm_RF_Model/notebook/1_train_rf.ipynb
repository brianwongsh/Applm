{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5bd546",
   "metadata": {},
   "source": [
    "# Training and testing Applm (RF model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf07e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubuntu                    22.04\n",
    "\n",
    "# miniconda3                24.1.2\n",
    "\n",
    "# python                    3.10.9 \n",
    "# numpy                     1.26.4\n",
    "# pandas                    1.5.3\n",
    "# scikit-learn              1.4.1.post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85961d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seq_pickle(seqid, embed=\"ohe\"):\n",
    "    # Define paths to where embeddings are stored\n",
    "    prefix_dict={\"ohe\":\"../0_embeddings/avgpool_ohe/\",\n",
    "                \"xtrimopglm_10b\":\"../0_embeddings/avgpool_xtrimopglm_10b/\"}\n",
    "    # Embedded seqeunce are saved as a pickle file which contains the embeddings themselves\n",
    "    # as a numpy array of shape (D, 1), and a label [0 or 1] as a numpy array of shape (1, ).\n",
    "    with open(os.path.join(prefix_dict[embed], seqid+\".pickle\"), \"rb\") as file:\n",
    "        x = cPickle.load(file)\n",
    "        y = cPickle.load(file)\n",
    "    return x, y\n",
    "\n",
    "def read_fasta(filepath):\n",
    "    \"\"\"\n",
    "    Reads a FASTA file and returns a dictionary of sequences.\n",
    "\n",
    "    The function parses a file in FASTA format, where each sequence is\n",
    "    preceded by a header line starting with '>'. It extracts the sequence\n",
    "    identifier from the header and the corresponding sequence.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to the FASTA file.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are sequence identifiers (str) and\n",
    "        values are the corresponding protein or nucleotide sequences (str).\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as file:\n",
    "        s1 = file.read()\n",
    "    s1 = s1.split(\">\")[1:]\n",
    "    fasta_dict = {}\n",
    "    for i in s1:\n",
    "        seq_id = i.split(\"\\n\")[0]\n",
    "        seq = ''.join(i.split(\"\\n\")[1:])\n",
    "        fasta_dict[seq_id] = seq\n",
    "    return fasta_dict\n",
    "\n",
    "def read_dataset(fasta_filepath, embed=\"ohe\"):\n",
    "    \"\"\"\n",
    "    Reads a FASTA file and returns the sequence names, embedded sequences, \n",
    "    and labels as 3 separate lists.\n",
    "\n",
    "    Args:\n",
    "        fasta_filepath: The path to the FASTA file.\n",
    "    \n",
    "    Returns:\n",
    "        Sequence names, embedded sequences, and labels as 3 separate lists.\n",
    "\n",
    "    \"\"\"\n",
    "    seqs = read_fasta(fasta_filepath)\n",
    "    seqid = list(seqs.keys())\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in seqs:\n",
    "        x_embed, y_label = read_seq_pickle(i, embed)\n",
    "        x.append(x_embed)\n",
    "        y.append(y_label)\n",
    "\n",
    "    x = np.array(x).squeeze()\n",
    "    y = np.array(y).squeeze()\n",
    "    return seqid, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e1577a",
   "metadata": {},
   "source": [
    "## 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671286d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2358/2358 [00:03<00:00, 589.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "embed = 'xtrimopglm_10b'\n",
    "seqid_train, x_train, y_train = read_dataset('../1_train_splits_fa/ex1/train.fa', embed)\n",
    "seqid_valid, x_valid, y_valid = read_dataset('../1_train_splits_fa/ex1/valid.fa', embed)\n",
    "seqid_test, x_test, y_test = read_dataset('../1_train_splits_fa/ex1/test.fa', embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd74f5",
   "metadata": {},
   "source": [
    "## 2. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "np.random.seed(42)\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, n_jobs=4, random_state = 42)\n",
    "clf.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869a9de",
   "metadata": {},
   "source": [
    "## 3. Saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_valid_hat = clf.predict_proba(x_valid)[:,1]\n",
    "y_test_hat = clf.predict_proba(x_test)[:,1]\n",
    "\n",
    "# Save predictions\n",
    "valid_df = pd.DataFrame({\"seqid\":seqid_valid,\"y_hat\":np.squeeze(y_valid_hat), \"y\":np.squeeze(y_valid)})\n",
    "valid_df.to_csv(\"../2_results/ex1/valid_labeled.csv\")\n",
    "\n",
    "test_df = pd.DataFrame({\"seqid\":seqid_test,\"y_hat\":np.squeeze(y_test_hat), \"y\":np.squeeze(y_test)})\n",
    "test_df.to_csv(\"../2_results/ex1/test_labeled.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

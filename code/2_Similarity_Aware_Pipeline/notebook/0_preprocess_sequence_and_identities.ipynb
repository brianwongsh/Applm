{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02c008f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import h5py\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0ecb4",
   "metadata": {},
   "source": [
    "This notebook assumes you have a fasta of sequences you want to cluster, and you have your own way of obtaining all-vs.-all sequence identity between sequences in the fasta.\n",
    "\n",
    "Once you have the fasta and the all-vs.-all sequence identities pre-computed (here it is provided in the form of a 2-d numpy array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afbbf31",
   "metadata": {},
   "source": [
    "## Step 1: Create the sequence to index mapping object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06deb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_fa = \"../../1_Computing_Similarity/example_input/ex3.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dfc75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_keys(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        s1 = file.read()\n",
    "    seq_keys = [i.split(\"\\n\")[0] for i in s1.split(\">\")[1:]]\n",
    "    return seq_keys\n",
    "\n",
    "seq_keys = sorted(get_seq_keys(toy_fa))\n",
    "key_to_idx = defaultdict(int)\n",
    "key_to_idx['placeholder'] = 0\n",
    "for ni, i in enumerate(seq_keys):\n",
    "    key_to_idx[i] = ni+1\n",
    "\n",
    "with open(\"../example_intermediate/ex3_key_to_idx.pickle\", 'wb') as file:\n",
    "    cPickle.dump(key_to_idx, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7687a47",
   "metadata": {},
   "source": [
    "# Step 2: Format identity matrix from ssearch36 formatted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_fa = \"../../1_Computing_Similarity/example_input/ex3.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac1a4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_keys(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        s1 = file.read()\n",
    "    seq_keys = [i.split(\"\\n\")[0] for i in s1.split(\">\")[1:]]\n",
    "    return seq_keys\n",
    "\n",
    "seq_keys = sorted(get_seq_keys(toy_fa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../1_Computing_Similarity/example_output/ex3_formatted', 'r') as file:\n",
    "    content = file.read()\n",
    "content = content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0516576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000001/1000001 [00:16<00:00, 60686.75it/s]\n"
     ]
    }
   ],
   "source": [
    "ident_mat = np.zeros((len(seq_keys), len(seq_keys)))\n",
    "\n",
    "for i in tqdm(content):\n",
    "    if len(i) > 0:\n",
    "        row = i.split(\"\\t\")\n",
    "        id1 = row[0]\n",
    "        id2 = row[1]\n",
    "        identity = float(row[2])\n",
    "        min_len = np.minimum(int(row[3]), int(row[4]))\n",
    "        aln_len = int(row[5])\n",
    "\n",
    "        # custom coverage control\n",
    "        coverage = min_len/aln_len\n",
    "        if coverage > 0.25:\n",
    "            ident_mat[seq_keys.index(id1), seq_keys.index(id2)] = identity\n",
    "        else:\n",
    "            ident_mat[seq_keys.index(id1), seq_keys.index(id2)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../example_input/ex3_pairwise_ident.npy', ident_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e0bee",
   "metadata": {},
   "source": [
    "# Step 3: Create the h5 object which stores and retrieves the pairwise identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a80d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is assumed you have pre-computed all pairwise distances / sequence similarity\n",
    "# It is assumed this array is also ordered according to the order of `seq_keys` above\n",
    "# i.e. identity of `seq_keys[0]` against `seq_keys[1]` can be found at `loaded_array[0, 1]`\n",
    "# Here, an example array of size `len(seq_keys) x len(seq_keys)` is provided where each \n",
    "# entry is the identity of a pair of sequences.\n",
    "loaded_array = np.load('../example_intermediate/ex3_pairwise_ident.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404ae54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 8614.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Create an HDF5 file\n",
    "# The actual H5 data structure will reserve the first row and first column as a \n",
    "# place-holder for any non-existing keys, which it will then return 0. i.e. the\n",
    "# H5 structure will be of size `(len(seq_keys)+1) x (len(seq_keys)+1)`\n",
    "with h5py.File('../example_intermediate/ex3.h5', 'w') as hdf:\n",
    "    hdf.create_dataset('0', data=np.zeros(loaded_array.shape[0] + 1, dtype=float))  # index 0 is reserved for placeholder\n",
    "    for ni, i in enumerate(tqdm(seq_keys)):\n",
    "        ident_list = loaded_array[ni]   # identities of sequence i against all of seq_keys\n",
    "        ident_list = np.concatenate([np.array([0.]), ident_list])   # index 0 is reserved for placeholder\n",
    "        hdf.create_dataset(str(key_to_idx[i]), data=ident_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0770a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
